{"cells":[{"metadata":{"trusted":true,"_uuid":"724311dcbde5385f05b1b4a35de8e6dbf8d5f374"},"cell_type":"code","source":"import matplotlib.pylab as plt\nimport numpy as np\nimport pandas as pd\nfrom keras import models, layers, optimizers\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nimport os\nos.listdir('../input/scene-classification')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"930a3596f3703757549eab5dbfe52256e3a70f58"},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os, cv2, re, random\nimport numpy as np\nimport pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras import layers, models, optimizers\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nimport os\nprint(os.listdir(\"../input/scene-classification/\"))\n\nTRAIN_DIR = '../input/scene-classification/train-scene classification/train/'\n# TEST_DIR = '../input/test_WyRytb0.csv/'\ntrain_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n\ny_test = pd.read_csv(\"../input/scene-classification/test_WyRytb0.csv\")\ny_train = pd.read_csv(\"../input/scene-classification/train-scene classification/train.csv\")\ny_train = y_train['label']\nfrom keras.utils import to_categorical\ny_train_categorical = to_categorical(y_train, 6)\n\ntrain_images_list = []\ntest_images_list = []\na = list(y_test['image_name'])\nfor i in train_images:\n    if str(i[63:]) not in a:\n        train_images_list.append(i)\n    if str(i[63:]) in a:\n        test_images_list.append(i)\n        \ndef atoi(text):\n    return int(text) if text.isdigit() else text\n\ndef natural_keys(text):\n    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n\ntrain_images_list.sort(key=natural_keys)\ntest_images_list.sort(key=natural_keys)\n\ndef prepare_data(list_of_images):\n    x = [] \n    for image in list_of_images:\n        x.append(cv2.resize(cv2.imread(image), (150,150), interpolation=cv2.INTER_CUBIC))     \n    return x\nX_train = prepare_data(train_images_list)\nX_test = prepare_data(test_images_list)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2b41bc66-0085-4636-b7e1-40d586995344","_uuid":"f3604b7cb5e50a8da67bc1f3d31f45229601fe4f","trusted":true},"cell_type":"code","source":"X_train_prime, X_val, y_train_prime, y_val = train_test_split(X_train, y_train_categorical, random_state = 6, train_size = .80)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntrain_generator = train_datagen.flow(np.array(X_train_prime), y_train_prime, batch_size = 32, shuffle = True)\nval_generator = val_datagen.flow(np.array(X_val), y_val, batch_size = 32, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"78494e63-8409-43b8-b6f0-0831a6840768","_uuid":"cff62c4e13e12a88e87a1181c807b32454bd091d","trusted":true},"cell_type":"code","source":"#import inception with pre-trained weights. do not include fully #connected layers\nXception_base = applications.resnet50(weights='imagenet', include_top=False)\n\n# add a global spatial average pooling layer\nx = Xception_base.outputï¿¼\nx = layers.GlobalAveragePooling2D()(x)\n# add a fully-connected layer\nx = layers.Dense(512, activation='relu')(x)\nx = layers.Dropout(.5)(x)\n# and a fully connected output/classification layer\npredictions = layers.Dense(6, activation='softmax')(x)\n# create the full network so we can train on it\nXception_transfer = models.Model(inputs=Xception_base.input, outputs=predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8dda4cf121f4b154739e65712b430c818862365"},"cell_type":"code","source":"Xception_transfer.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-5, momentum=0.9),\n              metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24bc7e455ca86d9e416040118b5baf6cd753f6e3"},"cell_type":"code","source":"history = Xception_transfer.fit_generator(\n                    train_generator,\n                    epochs=50,\n                    steps_per_epoch=1500,\n                    validation_data = val_generator,\n                    validation_steps = 300,\n                    workers = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91d5e35c8e5aa9c369e4af7b35576a23a43425e7"},"cell_type":"code","source":"history = Xception_transfer.fit_generator(\n                    train_generator,\n                    epochs=30,\n                    steps_per_epoch=1500,\n                    validation_data = val_generator,\n                    validation_steps = 300,\n                    workers = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9317a5860907d354781b432e1daf3d57526eea4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62426bb40443838b40cb1c179d7c81013ab23dda"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb8af9629aee7055786680de0a66ec8430a96315"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8be841bab812d208781978a1ad3bc533aa5ece09"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}